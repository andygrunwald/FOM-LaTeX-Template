\section{Einleitung}
Abstract
Gesichtserkennung durch \ac{KI} hat in den letzten Jahren bedeutend an Relevanz gewonnen. Nicht nur in der Industrie, sondern auch im Alltag von Privatpersonen spielt Künstliche Intelligenz eine erhebliche Rolle. Personen, die dabei von der Norm abweichen, werden in Zuge dessen oft nicht gleichwertig berücksichtigt. 

Die in der westlichen Welt eingesetzten Algorithmen werden oftmals nicht ausreichend diversifiziert  trainiert, wodurch Minderheiten nicht im gleichen Maße berücksichtigt werden. Dies kann negative Auswirkungen auf die betroffenen Gruppen haben.

Im Rahmen der vorliegenden Arbeit wird aufgezeigt werden, dass Gesichtserkennung gesellschaftlich unterrepräsentierte Personengruppen nicht gleichwertig erkennt gegenüber der gesellschaftlichen Norm. Zudem wird gezeigt werden, dass diese Ungleichheit durch die Covid-19 Pandemie bestärkt werden.

\subsection{Problemstellung}
Tagtäglich werden Menschen durch Gesichtserkennung mithilfe \ac{KI} analysiert und ausgewertet.

Beispiele dafür sind Cloud Fotobibliothek, welche dem Nutzer Bilder nach Personen, Ereignisse und Orte anzeigen. 

Fehlerkennung von Gesichtern vermehrt bei Minderheiten, 
durch die COVID-19 Pandemie hat sich noch erweitert

In der fortschreitenden Digitalisierung können sich Unternehmen nicht auf Prozesse durch \ac{KI} verlassen, wenn diese falsche Ergebnisse liefern. 

Führt \ac{KI} den Bewerbungsprozess durch und entscheidet, ob eine Person im Unternehmen eingestellt wird...
Imageschaden entstehen, Personen diskriminiert werden 
Wissen durch falsch ausgewähltes Personal schadet der Weiterentwicklung und der Wirtschaftlichkeit eines Unternehmens. 

\subsection{Zielsetzung}
Im Rahmen der dieser Arbeit wird untersucht, wie sich das Erkennen und Beurteilen von Gesichtern mithilfe von KI-Systemen durch unterrepräsentierte Personengruppen verschlechtert. 
Zudem wird gezeigt werden, dass diese Ungleichheit durch die COVID-19 Pandemie verstärkt werden.

- Ungleichheit aufzeigen
- Risiko für Unternehmen errechnen: wie viel Prozent arbeitet eine KI schlechter mit weniger Datenpunkte durch benachteiligte Personengruppe + Maske verstärkt

\subsection{Vorgehensweise}
- Literaturanalyse 
- Onlineumfrage Gesichter Menschen erkennen
- Experiment KI
- Auswertung und Vergleich 
- Risiko ermitteln -> Hypothese entwickeln -> nähere Beleuchtung wie viel Prozent arbeitet eine KI schlechter mit weniger Datenpunkte durch benachteiligte Personengruppe + Maske verstärkt